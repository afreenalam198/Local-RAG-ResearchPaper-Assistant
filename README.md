# ğŸ§  ResearchPal - Local RAG Research Paper Assistant 

![Python](https://img.shields.io/badge/Python-3.11%2B-blue.svg?style=flat&logo=python)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red?style=flat&logo=streamlit)
![LangChain](https://img.shields.io/badge/LangChain-RAG-yellow?style=flat)
![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-green?style=flat)

---

## ğŸ“Œ Overview
The **Research Paper Assistant** is a **local AI-powered chatbot** for literature/academic paper search and summarization.  
It leverages **Retrieval-Augmented Generation (RAG)** with **Ollama LLMs** and **ChromaDB** using  **LangChain** to deliver **accurate, private, and fast** answers from your uploaded PDFs.

---

## âœ¨ Features
- ğŸ“š **PDF-based RAG** â€” Query your research papers directly.
- ğŸ¤– **Runs Locally** â€” Uses Ollama, no internet required for inference.
- ğŸ” **Semantic Search** â€” Embedding-powered document retrieval.
- ğŸ’¬ **Interactive Chat** â€” Clean Streamlit interface.
- ğŸ›¡ **Data Privacy** â€” No data leaves your machine.
- **Two interfaces**:
  - ğŸ–¥ **Command-line mode** (`main.py`)
  - ğŸŒ **Streamlit web UI** (`streamlit_ui.py`)

---

## ğŸ›  Tech Stack
| Component         | Technology |
|------------------|------------|
| **LLM**          | [Ollama](https://ollama.ai) (llama3.2) |
| **Embeddings**   | [Ollama](https://ollama.ai) (mxbai-embed-large) |
| **Vector Store** | [ChromaDB](https://www.trychroma.com/) |
| **UI**           | [Streamlit](https://streamlit.io) |
| **Parsing**      | [UnstructuredPDFLoader](https://python.langchain.com/docs/integrations/document_loaders/unstructured_pdfloader/) |
| **Orchestration**| [LangChain](https://www.langchain.com/) |

---

## ğŸ“‚ Project Structure

Healthcare Research Assistant/
â”‚  
â”œâ”€â”€ main.py # CLI interface for research Q&A  
â”œâ”€â”€ streamlit_ui.py # Web UI using Streamlit  
â”œâ”€â”€ vector.py # PDF ingestion, embeddings, and retriever logic  
â”œâ”€â”€ requirements.txt # Python dependencies  
â””â”€â”€ README.md  

## ğŸ–¼ï¸ UI Preview
(Replace screenshot.png with your actual screenshot)

## ğŸ§  How It Works
PDF Parsing â†’ Extracts text, splits into smaller chunks using UnstructuredPDFLoader from LangChain.

Embedding â†’ Converts chunks into vectors using Ollama embeddings model (maxbai-embed-large).

Vector Storage â†’ Saves embeddings into ChromaDB for retrieval.

Retriever Search â†’ Finds top relevant chunks for a query.

RAG Prompting â†’ Passes retrieved chunks + user question to LLaMA 3.2.

Answer Generation â†’ Responds only with context from your papers.

## ğŸ“Œ Future Improvements
- Multi-PDF summarization
- Improved retrieval ranking
- Fine-tuning for medical terminology
- Export answers with citations